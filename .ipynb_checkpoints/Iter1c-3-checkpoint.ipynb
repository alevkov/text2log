{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config():\n",
    "\n",
    "    PROJECT_DIR = os.environ[\"PWD\"]\n",
    "    DATA_DIR = os.getenv('DATA_DIR', 'data/')\n",
    "    RESULTS_DIR = os.getenv('RESULTS_DIR', 'results/')\n",
    "    MODELS_DIR = os.getenv(\"MODELS_DIR\", 'models/')\n",
    "    LOGS_DIR = os.getenv(\"LOGS_DIR\", 'logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(X, y, num_s, num_e, ratio):\n",
    "    print('Stats:')\n",
    "    print(\"------------------------\")\n",
    "    print(\"------------------------\")\n",
    "    print(f'N(X) == N(y) == {len(y)}')\n",
    "    print(f'errs: {num_e}')\n",
    "    print(f'Clean data (N = {num_s}) ratio: {ratio}%')\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dir = \"dat-in-use/clean/\"\n",
    "y_train_dir = \"dat-in-use/trans/\"\n",
    "X_test_dir = \"dat-in-use/test/\"\n",
    "\n",
    "# Will notify if these values change\n",
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "\n",
    "# All of the characters and substring that would mark lines in the training data as \"faulty\"\n",
    "invalid_chars = set(\n",
    "    [\n",
    "        \":\",\n",
    "        \"+\",\n",
    "        \"#\",\n",
    "        \"@\",\n",
    "        \"Ö\",\n",
    "        \"á\",\n",
    "        \"ä\",\n",
    "        \"é\",\n",
    "        \"í\",\n",
    "        \"ñ\",\n",
    "        \"ó\",\n",
    "        \"ö\",\n",
    "        \"ú\",\n",
    "        \"ā\",\n",
    "        \"Ć\",\n",
    "        \"ć\",\n",
    "        \"ʻ\",\n",
    "        \"́\",\n",
    "        \"е\",\n",
    "        \"н\",\n",
    "        \"о\",\n",
    "        \"п\",\n",
    "        \"у\",\n",
    "        \"ш\",\n",
    "        \"ã\",\n",
    "        \"ï\",\n",
    "        \"ō\",\n",
    "        \"ū\",\n",
    "        \"ί\",\n",
    "        \"α\",\n",
    "        \"δ\",\n",
    "        \"ε\",\n",
    "        \"κ\",\n",
    "        \"ο\",\n",
    "        \"в\",\n",
    "        \"ὐ\",\n",
    "        chr(776),\n",
    "        \"ç\",\n",
    "        \"ē\",\n",
    "        'D',\n",
    "        'O',\n",
    "        'T'\n",
    "    ]\n",
    ")\n",
    "invalid_chars_X = set([\"(\", \")\", \"<\", \">\", \"_\", \",\"])\n",
    "invalid_markers = set([\"\\\\F\", \"TrueP\", \"\\\\x\", \"semantics_error\", \"Prog(\"])\n",
    "files_with_compound_preds = [20, 21, 15]\n",
    "\n",
    "\n",
    "def mark_if_faulty(line, file_idx, X=False):\n",
    "    if line == \"\":\n",
    "        print(file_idx)\n",
    "    if X and (\n",
    "        any((c in invalid_chars) for c in line)\n",
    "        or any((c in invalid_chars_X) for c in line)\n",
    "    ):\n",
    "        return \"syntax_error\"\n",
    "    # TODO: Refactor this hacky workaround\n",
    "    if line[0] == \"(\" and file_idx not in files_with_compound_preds:\n",
    "        return \"syntax_error\"\n",
    "    if any((m in line) for m in invalid_markers) or any(\n",
    "        (c in invalid_chars) for c in line\n",
    "    ):\n",
    "        return \"syntax_error\"\n",
    "    # Remove top-level parentheses from lambda expression\n",
    "    if line[0:4] == \"(exi\" and line[-1] == \")\":\n",
    "        line = line[1:-1]\n",
    "    if line[0:4] == \"(all\" and line[-1] == \")\":\n",
    "        line = line[1:-1]\n",
    "\n",
    "    return line\n",
    "\n",
    "\n",
    "def lines_from_file(direc, name, drop_punc=False, lower=True, drop_fullstop=True):\n",
    "    with open(direc + name) as f:\n",
    "        for l in f:\n",
    "            l = l.rstrip()\n",
    "            if drop_punc:\n",
    "                l = l.translate(table)\n",
    "            if lower:\n",
    "                l = l.lower()\n",
    "            if drop_fullstop and not drop_punc:\n",
    "                l = l[0:-1]\n",
    "            yield l\n",
    "\n",
    "\n",
    "def load_and_clean_data(start_idx=1, end_idx=17, skip_idx_list=None):\n",
    "    X, y = [], []\n",
    "\n",
    "    err = lambda x: x == \"syntax_error\"\n",
    "    X_name = lambda i: f\"concordance_{i}_clean.txt\"\n",
    "    y_name = lambda i: f\"concordance_{i}_clean.lam\"\n",
    "\n",
    "    # Load lines from files and mark those that are \"faulty\"\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        if i in skip_idx_list:\n",
    "            continue\n",
    "\n",
    "        X = X + [\n",
    "            mark_if_faulty(line, i, True)\n",
    "            for line in lines_from_file(X_train_dir, X_name(i), drop_fullstop=True)\n",
    "        ]\n",
    "        y = y + [\n",
    "            mark_if_faulty(line, i)\n",
    "            for line in lines_from_file(\n",
    "                y_train_dir, y_name(i), lower=False, drop_fullstop=False\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Save \"faulty\" line indices\n",
    "    err_idx_X = [i1 for i1 in range(len(X)) if err(X[i1])]\n",
    "    err_idx_y = [j1 for j1 in range(len(X)) if err(y[j1])]\n",
    "\n",
    "    err_idx = set(err_idx_X).union(set(err_idx_y))\n",
    "    num_err = len(err_idx)\n",
    "    num_samples = len(y) - num_err\n",
    "    clean_ratio = 100 - ((num_err / len(y)) * 100)\n",
    "\n",
    "    # Show stats about training data\n",
    "    print_stats(X, y, num_samples, num_err, clean_ratio)\n",
    "\n",
    "    # Remove \"faulty\" lines\n",
    "    for index in sorted(list(err_idx), reverse=True):\n",
    "        del X[index]\n",
    "        del y[index]\n",
    "\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "------------------------\n",
      "------------------------\n",
      "N(X) == N(y) == 93847\n",
      "errs: 9197\n",
      "Clean data (N = 84650) ratio: 90.20000639338498%\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [83795, 84650]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-087c3d92ce0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0mload_and_clean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/dev-K5LzAmEm/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/dev-K5LzAmEm/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/dev-K5LzAmEm/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [83795, 84650]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    *load_and_clean_data(1, 22, [8, 6]), test_size=0.2, random_state=45, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 67357\n",
      "Number of unique input tokens: 39\n",
      "Number of unique output tokens: 50\n",
      "WARNING: NEW Max sequence length for outputs: 162\n",
      "Dataset may be incompatible with older models.\n",
      "['\\t', '\\n', ' ', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '>', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i in range(0, len(X_train)):\n",
    "    # SOS == '\\n'\n",
    "    # EOS == '\\t'\n",
    "    y_train[i] = \"\\t\" + y_train[i] + \"\\n\"\n",
    "    \n",
    "    for char in X_train[i]:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in y_train[i]:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_X_len = max([len(txt) for txt in X_train])\n",
    "max_y_len = max([len(txt) for txt in y_train])\n",
    "\n",
    "print(\"Number of samples:\", len(X_train))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "\n",
    "if (max_X_len > max_encoder_seq_length):\n",
    "    print(\"WARNING: NEW Max sequence length for inputs:\", max_X_len)\n",
    "    print(\"Dataset may be incompatible with older models.\")\n",
    "    max_encoder_seq_length = max_X_len\n",
    "    \n",
    "if (max_y_len > max_decoder_seq_length):\n",
    "    print(\"WARNING: NEW Max sequence length for outputs:\", max_y_len)\n",
    "    print(\"Dataset may be incompatible with older models.\")\n",
    "    max_decoder_seq_length = max_y_len\n",
    "    \n",
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char to index\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(X_train), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(X_train), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(X_train, y_train)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Test Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# with open(X_test_dir + f\"{datetime.datetime()}_X_test.txt\", 'w+') as f:\n",
    "#     for line in X_test:\n",
    "#         f.write(f\"{line}\\n\")\n",
    "        \n",
    "# with open(X_test_dir + f\"{datetime.datetime()}_y_test.txt\", 'w+') as f:\n",
    "#     for line in y_test:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(\n",
    "            name=\"W_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.U_a = self.add_weight(\n",
    "            name=\"U_a\",\n",
    "            shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.V_a = self.add_weight(\n",
    "            name=\"V_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super(AttentionLayer, self).build(\n",
    "            input_shape\n",
    "        )  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print(\"encoder_out_seq>\", encoder_out_seq.shape)\n",
    "            print(\"decoder_out_seq>\", decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\"Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(\n",
    "                states, type(states)\n",
    "            )\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(\n",
    "                K.dot(inputs, self.U_a), 1\n",
    "            )  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print(\"Ua.h>\", U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print(\"Ws+Uh>\", Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"ei>\", e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(\n",
    "                states, type(states)\n",
    "            )\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print(\"ci>\", c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(\n",
    "            encoder_out_seq, axis=2\n",
    "        )  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step,\n",
    "            decoder_out_seq,\n",
    "            [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step,\n",
    "            e_outputs,\n",
    "            [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1])),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM (Sutskever et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "batch_size = 128  # Batch size for training.\n",
    "epochs = 300  # Number of epochs to train for.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, recurrent_dropout=0.333, return_state=True, name=\"encoder\")\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(\n",
    "    latent_dim,\n",
    "    recurrent_dropout=0.333,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    name=\"decoder\",\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_pred = decoder_dense(decoder_outputs)\n",
    "\n",
    "early_stop = EarlyStopping(patience=10, monitor=\"val_loss\")\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "\n",
    "full_model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "batch_size = 128  # Batch size for training.\n",
    "epochs = 300  # Number of epochs to train for.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = GRU(latent_dim, recurrent_dropout=0.333, return_state=True, name=\"encoder\")\n",
    "encoder_outputs, encoder_state = encoder(encoder_inputs)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_gru = GRU(\n",
    "    latent_dim,\n",
    "    recurrent_dropout=0.333,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    name=\"decoder\",\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_gru(decoder_inputs, initial_state=encoder_state)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_pred = decoder_dense(decoder_outputs)\n",
    "\n",
    "early_stop = EarlyStopping(patience=3, monitor=\"val_loss\")\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "\n",
    "full_model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional GRU + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 56\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 50  # Number of epochs to train for.\n",
    "recurrent_dropout_rate = 0.333\n",
    "dropout_rate=0.5\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# Encoder GRU\n",
    "encoder_gru = Bidirectional(\n",
    "    GRU(\n",
    "        latent_dim,\n",
    "        return_sequences=True,\n",
    "        return_state=True,\n",
    "        name=\"encoder_gru\",\n",
    "        recurrent_dropout=recurrent_dropout_rate\n",
    "    ),\n",
    "    name=\"bidirectional_encoder\",\n",
    ")\n",
    "encoder_out, encoder_fwd_state, encoder_back_state = encoder_gru(encoder_inputs)\n",
    "\n",
    "# Set up the decoder GRU, using `encoder_states` as initial state.\n",
    "decoder_gru = GRU(\n",
    "    latent_dim * 2,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    name=\"decoder_gru\",\n",
    "    recurrent_dropout=recurrent_dropout_rate\n",
    ")\n",
    "decoder_out, decoder_state = decoder_gru(\n",
    "    decoder_inputs,\n",
    "    initial_state=Concatenate(axis=-1)([encoder_fwd_state, encoder_back_state]),\n",
    ")\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name=\"attention_layer\")\n",
    "attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "# Concat attention input and decoder GRU output\n",
    "decoder_concat_input = Concatenate(axis=-1, name=\"concat_layer\")(\n",
    "    [decoder_out, attn_out]\n",
    ")\n",
    "\n",
    "# Dense layer\n",
    "dense = Dense(num_decoder_tokens, activation=\"softmax\", name=\"softmax_layer\")\n",
    "decoder_pred = dense(decoder_concat_input)\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "opt = Adam(\n",
    "    learning_rate=0.001, \n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999, \n",
    "    epsilon=1e-07, \n",
    "    amsgrad=True,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "# opt = tf.keras.optimizers.RMSprop(\n",
    "#     learning_rate=0.001,\n",
    "#     rho=0.9,\n",
    "#     momentum=0.0,\n",
    "#     epsilon=1e-07,\n",
    "#     centered=True,\n",
    "#     name=\"RMSprop\"\n",
    "# )\n",
    "\n",
    "# Full model\n",
    "full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "full_model.compile(\n",
    "    optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 48\n",
    "batch_size = 32  # Batch size for training.\n",
    "epochs = 30  # Number of epochs to train for.\n",
    "dropout_rate = 0.333\n",
    "recurrent_dropout_rate = 0.2\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# Encoder LSTM\n",
    "encoder_gru = Bidirectional(\n",
    "    LSTM(\n",
    "        latent_dim,\n",
    "        return_sequences=True,\n",
    "        return_state=True,\n",
    "        name=\"encoder_lstm\",\n",
    "        recurrent_dropout=recurrent_dropout_rate,\n",
    "    ),\n",
    "    name=\"bidirectional_encoder\",\n",
    ")\n",
    "(\n",
    "    encoder_out,\n",
    "    encoder_fwd_state_h,\n",
    "    encoder_fwd_state_c,\n",
    "    encoder_back_state_h,\n",
    "    encoder_back_state_c,\n",
    ") = encoder_gru(encoder_inputs)\n",
    "\n",
    "encoder_state_h = Concatenate()([encoder_fwd_state_h, encoder_fwd_state_c])\n",
    "encoder_state_c = Concatenate()([encoder_back_state_c, encoder_back_state_c])\n",
    "\n",
    "# Set up the decoder LSTM, using `encoder_states` as initial state.\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(\n",
    "    latent_dim * 2,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    recurrent_dropout=recurrent_dropout_rate,\n",
    "    name=\"decoder_lstm\",\n",
    ")\n",
    "decoder_out, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name=\"attention_layer\")\n",
    "attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name=\"concat_layer\")(\n",
    "    [decoder_out, attn_out]\n",
    ")\n",
    "\n",
    "# Dense layer\n",
    "dense = Dense(num_decoder_tokens, activation=\"softmax\", name=\"softmax_layer\")\n",
    "decoder_pred = dense(decoder_concat_input)\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "opt = Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=True,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "\n",
    "# opt = tf.keras.optimizers.RMSprop(\n",
    "#     learning_rate=0.001,\n",
    "#     rho=0.9,\n",
    "#     momentum=0.0,\n",
    "#     epsilon=1e-07,\n",
    "#     centered=True,\n",
    "#     name=\"RMSprop\"\n",
    "# )\n",
    "\n",
    "# Full model\n",
    "full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "full_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 39)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_encoder (Bidirect [(None, None, 112),  32592       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 50)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112)          0           bidirectional_encoder[0][1]      \n",
      "                                                                 bidirectional_encoder[0][2]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 112),  55104       input_2[0][0]                    \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 112),  25200       bidirectional_encoder[0][0]      \n",
      "                                                                 decoder_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 224)    0           decoder_gru[0][0]                \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax_layer (Dense)           (None, None, 50)     11250       concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 124,146\n",
      "Trainable params: 124,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.825, max:    0.998, cur:    0.998)\n",
      "\tvalidation       \t (min:    0.892, max:    0.998, cur:    0.998)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.008, max:    0.652, cur:    0.008)\n",
      "\tvalidation       \t (min:    0.007, max:    0.347, cur:    0.007)\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00655\n",
      "53885/53885 [==============================] - 572s 11ms/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 26/50\n",
      "42816/53885 [======================>.......] - ETA: 1:52 - loss: 0.0077 - accuracy: 0.9978"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Callbacks\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stop = EarlyStopping(patience=3, monitor=\"val_loss\")\n",
    "plot_loss = PlotLossesKeras()\n",
    "filepath=f\"models/checkpoint/weights-bilstm-N({len(X_train)})-{latent_dim}.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Start Training\n",
    "history = full_model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, plot_loss, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save(f\"models/i1c-2-N({len(X_train)})-{latent_dim}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_bigru_attn(\n",
    "    encoder_model, decoder_model, test_X_seq, num_encoder_tokens, num_decoder_tokens\n",
    "):\n",
    "    \"\"\"\n",
    "    Infer logic\n",
    "    :param encoder_model: keras.Model\n",
    "    :param decoder_model: keras.Model\n",
    "    :param test_X_seq: sequence of word ids\n",
    "    :param num_encoder_tokens: int\n",
    "    :param num_decoder_tokens: int\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    enc_outs, enc_fwd_state, enc_back_state = encoder_model.predict(test_X_seq)\n",
    "    dec_state = np.concatenate([enc_fwd_state, enc_back_state], axis=-1)\n",
    "    attention_weights = []\n",
    "    y_text = \"\"\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        dec_out, attention, dec_state = decoder_model.predict(\n",
    "            [enc_outs, dec_state, target_seq]\n",
    "        )\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(dec_out, axis=-1)[0, 0]\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        attention_weights.append((sampled_token_index, attention))\n",
    "\n",
    "    return decoded_sentence, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_bilstm_attn(\n",
    "    encoder_model, decoder_model, test_X_seq, num_encoder_tokens, num_decoder_tokens\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_lstm(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "\n",
    "def plot_attention_weights(\n",
    "    encoder_inputs, attention_weights, en_id2word, fr_id2word, filename=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots attention weights\n",
    "    :param encoder_inputs: Sequence of word ids (list/numpy.ndarray)\n",
    "    :param attention_weights: Sequence of (<word_id_at_decode_step_t>:<attention_weights_at_decode_step_t>)\n",
    "    :param en_id2word: dict\n",
    "    :param fr_id2word: dict\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    if len(attention_weights) == 0:\n",
    "        print(\n",
    "            \"Your attention weights were empty. No attention map saved to the disk. \"\n",
    "            + \"\\nPlease check if the decoder produced  a proper translation\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    mats = []\n",
    "    dec_inputs = []\n",
    "    for dec_ind, attn in attention_weights:\n",
    "        mats.append(attn.reshape(-1))\n",
    "        dec_inputs.append(dec_ind)\n",
    "    attention_mat = np.transpose(np.array(mats))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(32, 32))\n",
    "    ax.imshow(attention_mat)\n",
    "\n",
    "    ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
    "    ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
    "\n",
    "    ax.set_xticklabels([fr_id2word[inp] if inp != 0 else \"<Res>\" for inp in dec_inputs])\n",
    "    y_lab = [\n",
    "        en_id2word[inp]\n",
    "        for inp in [\n",
    "            np.argmax(np.squeeze(encoder_inputs)[i])\n",
    "            for i in range(0, np.squeeze(encoder_inputs).shape[0])\n",
    "        ]\n",
    "    ]\n",
    "    ax.set_yticklabels(y_lab)\n",
    "\n",
    "    ax.tick_params(labelsize=16)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "    if not os.path.exists(config.RESULTS_DIR):\n",
    "        os.mkdir(config.RESULTS_DIR)\n",
    "    if filename is None:\n",
    "        plt.savefig(os.path.join(config.RESULTS_DIR, \"attention.png\"))\n",
    "    else:\n",
    "        plt.savefig(os.path.join(config.RESULTS_DIR, \"{}\".format(filename)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-GRU + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inf_inputs = Input(shape=(None, num_encoder_tokens), name=\"encoder_inf_inputs\")\n",
    "encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state = encoder_gru(\n",
    "    encoder_inf_inputs\n",
    ")\n",
    "encoder_model = Model(\n",
    "    inputs=encoder_inf_inputs,\n",
    "    outputs=[encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state],\n",
    ")\n",
    "\n",
    "\"\"\" Decoder (Inference) model \"\"\"\n",
    "decoder_inf_inputs = Input(shape=(None, num_decoder_tokens), name=\"decoder_inf_inputs\")\n",
    "encoder_inf_states = Input(\n",
    "    batch_shape=(None, None, 2 * latent_dim), name=\"encoder_inf_states\"\n",
    ")\n",
    "decoder_init_state = Input(batch_shape=(None, 2 * latent_dim), name=\"decoder_init\")\n",
    "\n",
    "decoder_inf_out, decoder_inf_state = decoder_gru(\n",
    "    decoder_inf_inputs, initial_state=decoder_init_state\n",
    ")\n",
    "attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name=\"concat\")(\n",
    "    [decoder_inf_out, attn_inf_out]\n",
    ")\n",
    "decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "decoder_model = Model(\n",
    "    inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "    outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Saved HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set these parameters (embedded in file name)\n",
    "latent_dim = 56\n",
    "len_X = 66980\n",
    "# loaded_model = load_model(\"models/i1b-128.h5\")\n",
    "loaded_model = load_model(f\"models/i1c-2-N({len_X})-{latent_dim}.h5\", custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.load_weights(f\"models/checkpoint/weights-bilstm-N({len(X_train)})-{latent_dim}.best.hdf5\")\n",
    "# loaded_model.load_weights(f\"models/checkpoint/weights-bigru-N(67374)-56.best.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = loaded_model.layers[2]\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_dense = loaded_model.layers[4]\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = loaded_model.layers[3]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, \n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-GRU + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inf_inputs = Input(shape=(None, num_encoder_tokens), name=\"encoder_inf_inputs\")\n",
    "encoder = full_model.layers[1]\n",
    "encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state = encoder(\n",
    "    encoder_inf_inputs\n",
    ")\n",
    "encoder_model = Model(\n",
    "    inputs=encoder_inf_inputs,\n",
    "    outputs=[encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state],\n",
    ")\n",
    "\n",
    "\"\"\" Decoder (Inference) model \"\"\"\n",
    "decoder_inf_inputs = Input(shape=(None, num_decoder_tokens), name=\"decoder_inf_inputs\")\n",
    "encoder_inf_states = Input(\n",
    "    batch_shape=(None, None, 2 * latent_dim), name=\"encoder_inf_states\"\n",
    ")\n",
    "decoder_init_state = Input(batch_shape=(None, 2 * latent_dim), name=\"decoder_init\")\n",
    "\n",
    "decoder = full_model.layers[4]\n",
    "dense = full_model.layers[7]\n",
    "decoder_inf_out, decoder_inf_state = decoder(\n",
    "    decoder_inf_inputs, initial_state=decoder_init_state\n",
    ")\n",
    "attn_layer = full_model.layers[5]\n",
    "attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name=\"concat\")(\n",
    "    [decoder_inf_out, attn_inf_out]\n",
    ")\n",
    "decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "decoder_model = Model(\n",
    "    inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "    outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = ['all races start and finish', 'he made her day', 'he fixes cars and trucks', 'he is willing and able', 'he is willing or able', 'some men are abe-lincoln', 'all boys like piano and guitar', 'some men were astronauts and some women were engineers']\n",
    "\n",
    "\n",
    "encoder_test_data = np.zeros(\n",
    "    (len(X_test), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "for i, x in enumerate(X_test):\n",
    "    for t, char in enumerate(x):\n",
    "        encoder_test_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_test_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "correct = 0\n",
    "checked = 0\n",
    "for seq_index in range(0, len(X_test)):\n",
    "    test_X = X_test[seq_index]\n",
    "    input_seq = encoder_test_data[seq_index : seq_index + 1]\n",
    "    \n",
    "    # Bi-GRU\n",
    "    decoded_sentence, attn_weights = decode_sequence_bigru_attn(\n",
    "        encoder_model, decoder_model, input_seq, num_encoder_tokens, num_decoder_tokens\n",
    "    )\n",
    "    \n",
    "    # LSTM\n",
    "    # decoded_sentence = decode_sequence_lstm(input_seq)\n",
    "#     plot_attention_weights(\n",
    "#         input_seq,\n",
    "#         attn_weights,\n",
    "#         reverse_input_char_index,\n",
    "#         reverse_target_char_index,\n",
    "#         filename=\"attention_{}.png\".format(seq_index),\n",
    "#     )\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", X_test[seq_index])\n",
    "    print(\"Decoded sentence:\", repr(decoded_sentence.rstrip()))\n",
    "#     print(\"Real sentence:\", repr(y_test[seq_index]))\n",
    "#     print(\"CORRECT\" if decoded_sentence.rstrip() == y_test[seq_index] else \"INCORRECT\")\n",
    "#     correct += 1 if decoded_sentence.rstrip() == y_test[seq_index] else 0\n",
    "#     checked += 1\n",
    "#     print(f\"Checked: {(checked / len(X_test)) * 100}%\")\n",
    "#     print(\"Accuracy:\")\n",
    "#     print(f\"{(correct / checked) * 100}%\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
